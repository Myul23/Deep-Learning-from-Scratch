# Chapter 8. 딥러닝
# 8.1 더 깊게
# Batch Normalization을 이용해 한 번에 소량의 데이터로 학습시키기부터 일반적인 학습 형태인 행렬곱 연산과 편향과의 덧셈 또는 이미지 및 다차원 데이터를 위한 Convolution 계층, 다음 층을 위해 신호로 변환하는 Sigmoid, ReLU 등, 나아가 CNN에서 데이터를 줄이는 데 이용되는 Pooling, init_weight을 위한 std 이용법, Sigmoid: Xavier 초깃값, ReLU: he 초깃값, SGD, Adam, AdaGrad etc.

# 8.1.1 더 깊은 신경망으로
# input - Conv - ReLU - Conv - ReLU - Pool - Conv - ReLU - Conv - ReLU - Pool - Conv - ReLU - Conv - ReLU - Pool - Affine - ReLU - Dropout - Affine - Dropout - Softmax - output
# 모두 3x3 크기의 filter, 채널 수가 16, 16, 32, 32, 64, 64로 증가, ReLU로 He 초깃값 이용, Adam 사용, 완전 연결 계층에서만 Dropout

# 잘못 예측한 것들을 보면 인간과 비슷한 인식 수준의 차이를 보이고 있음을 알 수 있음.

# 8.1.2 정확도를 높이려면
# https://rodrigob.github.io/are_we_there_yet/build/classification_datasets_results.html
# Mnist 데이터 판별을 위한 모형은 많음.
# 이들을 살펴보면 은닉층의 수는 그리 많지 않음. 앙상블 학습, 학습률 감소, 데이터 확장 등의 다양한 기법을 통해 정확도를 개선하고 있음.

# 여기서 데이터 확장이란, 입력 이미지를 회전시키거나 이동해서 데이터의 전체적인 형태에 대해 더 주목하게 하는 것. 특히 데이터가 적을 때 효과적. (배깅, 부스팅 등의 앙상블 학습의 일종처럼 보이지.)
# 나아가 조금 더 형태에 주목하고자 한다면, 전체적인 밝기를 바꾼다든지 확대나 축소를 한다든지, 외형을 일부 조정한다든지
# 단순히 조금 다른 형태의 데이터를 이용하는 거지만, 모형의 예측에 꽤 기여한다고.

# 8.1.3 깊게 하는 이유
# 이론적인 근거는 아직 부족한 편
# 대규모 이미지 인식 대회를 보자면, 층의 깊이에 비례해 정확도가 좋아짐.
# (이것도 한 층과 두 층으로 해봐야 하는 걸까.)

# 3x3 filter로 연산하는 걸 보면, 처음은 데이터를 중심으로 3x3 영역의 영향을 받고, 그 다음 층에선 5x5의 영향을 받고, 그 다음에선 7x7의 영향을 받음.
# 이렇게 층이 깊어질수록 더 포괄적인, 전체적인 이미지의 형태를 생각할 수 있게 됨.
# 나아가 원래 7x7를 보려면 49개의 weight이 필요했지만, 3x3x3이므로 27밖에 사용하지 않음.
# 학습할 매개변수가 줄면서 더 빠르게 학습

# 전체적으로 보자면, 노이즈에 덜 민감하기 위해 많은 양의 데이터와 학습이 필요했음.
# 그러나 딥러닝은 사물이 가진 패턴, 작은 단위의 형태를 분석하고 조합하므로써 빠르게 학습할 수 있고, 노이즈와 같은 요인들을 배제하여 더 나은 결과를 내는 거지.
# 다시 말해 복잡한 문제를 몇 가지의 단순 문제의 조합으로 이해하는 거지.
# 나아가 CNN에서 초기 계층이 다양한 형태의 선을 인식하는 거라면, 그 다음 층에선 확인된 선을 조합해서 도형을 인식할 수 있으니까.
