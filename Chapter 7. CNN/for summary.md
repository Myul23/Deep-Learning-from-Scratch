## Chapter 7 합성곱 신경망 (CNN)

- CNN: Convolutional Neural Network
- 이미지 인식 뷴야에서 딥러닝을 활용한 기법은 거의 다 CNN을 기초로 함.

### 7.1 전체 구조

#### 완전연결

- fully-connected (layer), 전결합

> 합성곱은 공학과 물리학에서 널리 쓰이는 수학적 개념으로, 간단히 정의해보면 다음과 같습니다.<br />두 함수 중 하나를 반전(reverse), 이동(shift)시켜 가며 나머지 함수와의 곱을 연이어 적분한다.

출력에 가까운 층은 지금까지처럼 Affine - ReLU의 구성을 유지하고, 나머지(입력에 가까운 층)는 Conv - ReLU - Pooling으로 구성하는 것이 CNN

### 7.2 합성곱 계층

- 새로운 용어(padding, stride 등)의 등장
- 각 계층 사이에 입체적인(다차원) 데이터가 흐른다는 점에서 완전연결 신경망과 다릅니다.

#### 7.2.1 완전연결 계층의 문제점

완전연결 계층: 인접하는 계층의 뉴런이 모두 연결되고 출력의 수는 임의로 정할 수 있음
- 문제점: 입력 데이터의 형상 무시
- (1, 1, 28, 28) -> flatten -> (1, 784) -> Affine에 입력으로 이용

합성곱 계층: 차원이라는 새로운 global 변수가 추가됨을 인식하고 연산에 참여하게 함
- 입력도 다차원, 출력도 다차원
- 따라서 CNN에서는 이미지처럼 형상을 가진 데이터를 제대로 이해할 (가능성이 있는) 것.
- 특징 맵 (feature map): 입력 데이터(input feature map), 출력 데이터 ((output) feature map)
- 합성곱 계층에서 합성곱 연산 = 이미지 처리에서 필터 연산

|  word  |            | concept                                               |
| :----: | ---------- | ----------------------------------------------------- |
| filter | 필터, 커널 | 합성곱 연산에서 곱해지는 값의 모임(집단)              |
| window | 윈도우     | 이번 단계(반복)에서 filter와 연산하는 데이터들 (형상) |

입력과 필터에서 대응하는 원소끼리 곱한 후 그 총합을 구하는 걸 단일 곱셈-누산 (fused multiply-add)이라 하고, 모든 장소에서 수행하면 합성곱 연산의 출력이 완성됩니다.

> 과학, 공학용 파이썬 라이브러리인 SciPy의 2차원 합성곱 함수(scipy.signal.convolve2d)로 이 예를 따라 해보면 결과가 다르게 나옵니다. 같은 결과를 얻으려면 합성곱이 아니라 교차상관(cross-correlation) 함수인 scipy.signal.correlate2d를 사용해야 하는데, 이유가 뭘까요?

> 주어진 필터를 플리핑(flipping)하면 합성곱이고, 그렇지 않으면 교차상관입니다. 이때 플리핑이란 transpose를 의미하는데, SciPy는 그 둘을 명확히 구분하나 딥러닝 쪽에서는 잘 구분하지 않는 경향이 있습니다.

> 딥러닝에서 이야기하는 합성곱은 엄연히 자연과학에서 얘기하는 합성곱과 달리 교차상관입니다.

<!-- 결과적으로 합성곱 또한 행렬곱을 극한으로 확장한 격이다. -->

#### 7.2.3 패딩

입력 데이터 주변을 특정값(0)으로 채우는 기법
- 기본적으로 패딩은 이후 연산에 큰 영향을 주지 못하도록 0으로 채운다.
- 사실 주변값과 비슷하게 채우는 건 연산에 큰 영향을 주려나 싶다.

#### 7.2.4 스트라이드

필터를 적용하는 위치의 간격
- 이전 윈도우와 다음 윈도우 칸의 차이

```
OH = (H + 2P - FH)/S + 1
OW = (W + 2P - FW)/S + 1
```

결과적으로 패딩을 통해 출력의 형상을 키울 수도 있고, 스트라이드를 통해 줄일 수도 있다.

### 7.3 풀링 계층

세로, 가로 방향의 공간을 줄이는 연산
- 보통 풀링의 윈도우 크기와 스트라이드는 같은 값으로 설정한다.
- 최대풀링 말고도 많은 sub-sampling 방법이 있지만, 이미지 인식 분야에서 주로 최대풀링을 이용한다.

#### 7.3.1 풀링 계층의 특징

- 학습해야 할 매개변수가 없다
- 채널 수가 변하지 않는다.
- 입력의 변화에 영향을 적게 받는다 (강건하다)
  - 잡음 제거 효과를 볼 수 있다

### 7.4 합성곱/풀링 계층 구현하기

#### 7.4.2 im2col로 데이터 전개하기

<!-- numpy에선 for 문을 사용하지 않는 것이 바람직 -->

im2col: 입력 데이터를 계산 단위에 맟춰 펼치는(2차원으로 변환시키는) 함수
- 이미지 데이터에 대해선 각 윈도우를 flatten하여 행병합시켜 2차원으로 변형합니다.
- 각 filter를 행렬곱하기 편하도록 (N, 1)로 펼쳐 열병합시키면 im2col의 변환 트릭 완성

연산을 진행한 후에는 col2im 함수를 통해 계산상 output 형상이 되어야 했을 모양으로 형상을 바꾸면 연산 끝

#### 7.4.4 풀링 계층 구현하기

1. 입력 데이터를 전개한다
2. (Max-Pooling) 행렬 최댓값을 구한다
3. 적절한 모양으로 성형한다.

### 7.6 CNN 시각화하기

#### 7.6.1 1번째 층의 가중치 시각화하기

학습 이후의 가중치를 이미지로 출력해보면 이미지 처리의 필터 연산으로 이용되는 특정 커널이 됨을 알 수 있다. 다시 말해 이미지 processing의 첫번째 은닉층은 선을 특정 위치의 직선이나 곡선을 검출하는 형식이 된다.

따라서 학습된 가중치는 자신이 가진 모양 엣지의 반응하는 필터가 된다.

#### 7.6.2 층 깊이에 따른 추출 정보 변화

처음 층은 그저 단순한 엣지만을 검출하는 데 그쳤지만, 층이 깊어지면서 특별한 형태의 도형이나 어떤 사물(사물의 일부분부터 더 깊어지면 그 사물 자체)를 검출할 수 있게 된다.

다시 말해 가중치 필터가 검출하고자 하는 모형의 형태로 변화한다.

이를 층이 깊어지면서 더 복잡하고 추상화된 정보가 추출된다고 하는 것.
- 사물의 의미를 이해하도록 변화한다고도 함.

### 7.7 대표적인 CNN

1. LeNet

input (32, 32) -> Convolutional (6, 28, 28) -> Subsampling (6, 14, 14) -> Convolutional (16, 10, 10) -> Subsampling (16, 5, 5) -> Full Connection (120) -> Full Connection (64) -> Gaussian Connections (10)

현재의 CNN과 다른 점

- Activation: Sigmoid
- Subsampling

그렇지만, LeNet이 지금부터 거의 20년 전에 제안된 첫 CNN이라는 점

2. AlexNet

input (3, 224, 224) -> Convolutional (96, 55, 55) -> Max-Pooling (256, 27, 27) -> Max-Pooling (384, 13, 13) -> Convolutional (384, 13, 13) -> Convolutional (256, 13, 13) -> Full Connection (4096) -> Full Connection (4096) -> Full Connection (1000)

특이점

- Activation: ReLU
- LRN (Local Response Normalization, 국소적 정규화)
- Dropout

사실 LeNet과 AlexNet의 차이는 크게 없음. 그저 컴퓨터가 많이 발전했을 뿐.<br />
빅데이터와 GPU, 이것이 딥러닝 발전의 큰 원동력
