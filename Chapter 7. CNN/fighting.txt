Affine과 Convolution의 궁극적인 차이는 Affine은 행, 열 단위의 계산이고, Convolution은 윈도우가 계산 단위라는 거?

## 7.6 CNN 시각화하기

1. randn을 통해 임의로 뽑힌 초기 가중치를 시각화
2. 앞선 train(SimpleNet)을 통해 학습된 가중치를 시각화

CNN에서 filter 연산은 원소간 곱이므로 하얀 형태의 값들이 출력의 주를 이루게 됨.
- 이걸 적당히 작은 그림으로 보여줘야 하나 고민 중

### 7.6.2 층 깊이에 따른 추출 정보 변화
계층이 깊어질수록 추출되는 정보는 더 추상화된다?
초기 계층이 선을 인식했다면 그 다음은 도형을 그 다음은 글씨를 그 다음은 어떤 형태를 다음은 사물을
마지막 완전연결 계층에선 각 형태가 다른 클래스라고 구분 짓는다고.
그래서 층이 깊어질수록 더 복잡한 형태를 인식하는 거고, 확인하고 비교하는 범위, 단위를 생각하면 추상화되는 거고.
결과적으로 사물의 의미를 이해하도록 변화하는 것.

SimpleNet의 2층, 3층의 가중치를 시각화 해보자?

## 7.7 대표적인 CNN

### 7.7.1 LeNet

CNN의 기원이자 첫 CNN, LeNet
CNN과는 Activation function이 SIgmoid라는 차이, max-pooling이 아닌 sub-sampling을 이용했다는 차이가 있음.

### 7.7.2 AlexNet

최근 CNN이라 Activation function이 ReLU, 국소적 정규화를 실시하는 계층을 이용, 드랍아웃을 사용

# 8. 딥러닝

## 8.1 더 깊게

Batch Normalization을 이용해 한 번에 소량의 데이터로 학습시키기부터
일반적인 학습 형태인 행렬곱 연산과 편향과의 덧셈 또는 이미지 및 다차원 데이터를 위한 Convolution 계층,
다음 층을 위해 신호로 변환하는 Sigmoid, ReLU 등, 나아가 CNN에서 데이터를 줄이는 데 이용되는 Pooling,